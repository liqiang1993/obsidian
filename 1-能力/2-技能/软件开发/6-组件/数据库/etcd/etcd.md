# 什么是etcd
[etcd](https://etcd.io/)（读作 et-see-dee）是一种[开源的](https://www.redhat.com/zh/topics/open-source/what-is-open-source)分布式统一键值存储，用于分布式系统或计算机集群的共享配置、服务发现和的调度协调

# etcd 诞生背景
etcd v2 源自 CoreOS 团队遇到的服务协调问题，理想中的协调服务核心目标：高可用、数据一致性、Watch、良好的可维护性等。而在 CoreOS 团队看来，高可用、可维护性、适配云、简单的 API、良好的性能对他们而言是非常重要的，ZooKeeper 无法满足所有诉求，因此决定自己构建一个分布式存储服务

# etcd v2的核心技术点
![[Pasted image 20220707090705.png]]

# etcd v2 的问题
![[Pasted image 20220707090820.png]]


# etcd v3的整体架构图
![[Pasted image 20220708090128.png]]

# etcd v3各功能模块及其作用

# etcd  v3读请求的流程
读请求根据对数据一致性的敏感度高低分为串性读和线性读， 串性度适用于低敏感度的业务场景，线性读适用于高敏感型的业务场景；

## 串性读
客户端根据负载均衡算法选择server，使用grpc协议与server建立长链接，  server直接读取blotdb的数据返回。 
优点：是性能高；
缺点：是可能存在读取的结果滞后于最新值的情况；

## 线性读
客户端根据负载均衡算法选择server，使用grpc协议与server建立长链接， server向集群leader server发送readindex请求，获取当前最新的版本值，server所在节点的版本赶上leader返回的版本时，返回server所在节点存储的数据；

优点：能准确读取集群一致性数据；
缺点：存在一定的性能损耗；


# etcd3写请求的流程
1.客户端通过负载均衡算法选择服务节点，发起grpc请求；
2.服务端的quote模块检查是否存在配额超限的情况；
3.kvserver模块进行限速、鉴权、文件大小等一系列检查后生成请求内容，通过channel发送给raft模块；
4.raft模块将数据存储到wal文件中，并将更改同步给follower节点，一半以上的follower节点wal持久化完成后，raft模块通过channel将 数据传递给apply模块；
5.apply模块通过consistent index 和事务实现了幂等性；
6.apply调用mvcc（虚拟模块），更新treeindex(version每次更新递增，初始化时遍历现存数据的最大version得到)，更新boltdb（内置数据库），为降低持久化数据的成本，会采取异步、批量提交事务的方式进行持久化。在数据未持久化期间，在boltdb中是查不到相关数据的，因此在bucket buffer(内存)中存放待提交的事务数据，可以保证数据查询的一致性和效率；


# etcd3利用raft算法实现高可用性和数据强一致性
## 单点故障的通用解决方案 -- 多副本复制
###  全同步复制
全部副本都确认后才返回操作结果
### 半同步复制
至少有一个副本确认后才返回操作结果
### 异步复制
主收到请求处理成功后直接返回
### 去中心化复制
节点间没有主从之分，都可以执行写入，假设有n个节点，至少写入w个节点才算成功，至少读取r个节点才算成功；

## 多副本复制存在的问题
根据cap理论，在可用性和一致性之间平衡，基于复制算法的数据库大多实现的是最终一致性，未能实现强一致性；在这个背景下，raft算法有了用武之地；



## raft共识算法
共识算法，它最早是基于复制状态机背景下提出来的。 下图是复制状态机的结构（引用自 Raft paper）， 它由共识模块、日志模块、状态机组成。通过共识模块保证各个节点日志的一致性，然后各个节点基于同样的日志、顺序执行指令，最终各个复制状态机的结果实现一致。

共识算法的祖师爷是 Paxos， 但是由于它过于复杂，难于理解，工程实践上也较难落地，导致在工程界落地较慢。standford 大学的 Diego 提出的 Raft 算法正是为了可理解性、易实现而诞生的，它通过问题分解，将复杂的共识问题拆分成三个子问题，分别是：
1.Leader 选举，Leader 故障后集群能快速选出新 Leader；
2.日志复制， 集群只有 Leader 能写入日志， Leader 负责复制日志到 Follower 节点，并强制 Follower 节点与自己保持相同；
3.安全性，一个任期内集群只能产生一个 Leader、已提交的日志条目在发生 Leader 选举时，一定会存在更高任期的新 Leader 日志中、各个节点的状态机应用的任意位置的日志条目内容应一样等。

### leader选举
节点的角色&角色转换：
1.follower: 节点初始状态
2.candinate: 接受leader心跳超时后进入选举状态
3.leader: 被过半数节点选举出来，一个集群只有一个，需要定时给follower发送心跳包；

任期号：随着每次选举更新；

PreCandidate：预投票，此阶段不更新任期号；

![[Pasted image 20220713100242.png]]

### 日志复制
一个日志条目被确定为已提交的前提是，它需要被 Leader 同步到一半以上节点上
![[Pasted image 20220713101015.png]]
![[Pasted image 20220713101109.png]]

### 安全性
选举规则：
当节点收到选举投票的时候，需检查候选者的最后一条日志中的任期号，若小于自己则拒绝投票。如果任期号相同，日志却比自己短，也拒绝为其投票。

日志复制规则：
1.Leader 完全特性：是指如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有 Leader 中。
2.只附加原则：Leader 只能追加日志条目，不能删除已持久化的日志条目。
3.日志匹配特性：Leader 在发送追加日志 RPC 消息时，会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。Follower 节点会检查相同索引位置的任期号是否与 Leader 一致，一致才能追加。




# etcd3的鉴权模块
## 一个好的健全模块需要满足如下 几个特点：
1.安全性
2.性能
3.扩展性
4.性能

## 整体鉴权架构
etcd3的鉴权架构分为控制面和数据面，控制面负责用户、密码、权限的管理；数据面处理认证、鉴权的具体逻辑
![[Pasted image 20220714093936.png]]


# etcd3的租约机制
![[Pasted image 20220715085810.png]]

# MVCC
MVCC 机制正是基于多版本技术实现的一种乐观锁机制，它乐观地认为数据不会发生冲突，但是当事务提交时，具备检测数据是否冲突的能力

## 锁的分类
1.悲观锁
2.乐观锁
3.两阶段锁：两阶段锁协议，**整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁**。 在加锁阶段，事务只能加锁，也可以操作数据，但不能解锁，直到事务释放第一个锁，就进入解锁阶段，此过程中事务只能解锁，也可以操作数据，不能再加锁。 两阶段锁协议使得事务具有较高的并发度，因为解锁不必发生在事务结尾。

## mvcc的整体架构
![[Pasted image 20220715100247.png]]

## mvcc的数据删除
使用的是标记删除，真正的删除操作是压缩组件执行压缩时删除的，故在压缩之前误删的数据可以恢复；


# watch机制
Watch 特性设计实现的四个核心问题，分别是获取事件机制、事件历史版本存储、如何实现可靠的事件推送机制、如何高效的将事件与 watcher 进行匹配。在获取事件机制、事件历史版本存储两个问题中，我给你介绍了 etcd v2 在使用 HTTP/1.x 轮询、滑动窗口时，存在大量的连接数、丢事件等问题，导致扩展性、稳定性较差。而 etcd v3 Watch 特性优化思路是基于 HTTP/2 的流式传输、多路复用，实现了一个连接支持多个 watcher，减少了大量连接数，事件存储也从滑动窗口优化成稳定可靠的 MVCC 机制，历史版本保存在磁盘中，具备更好的扩展性、稳定性。在实现可靠的事件推送机制问题中，我通过一个整体架构图带你了解整个 Watch 机制的核心链路，数据推送流程。Watch 特性的核心实现模块是 watchableStore，它通过将 watcher 划分为 synced/unsynced/victim 三类，将问题进行了分解，并通过多个后台异步循环 goroutine 负责不同场景下的事件推送，提供了各类异常等场景下的 Watch 事件重试机制，尽力确保变更事件不丢失、按逻辑时钟版本号顺序推送给 client。最后一个事件匹配性能问题，etcd 基于 map 和区间树数实现了 watcher 与事件快速匹配，保障了大规模场景下的 Watch 机制性能和读写稳定性。

# 理想的协调服务需要满足的功能点
1.可用性角度：高可用
2.数据一致性角度：提供读取“最新”数据的机制
3.容量角度：低容量、仅存储关键元数据配置
4.功能角度：增删改查，监听数据变化的机制
5.运维复杂度：可维护性。自动化运维或者提供api运维，尽可能规避人工运维；



# etcd与zookeeper的对比
## 共同点
从高可用性、数据一致性、功能这三个角度， 二者不相上下；

## zookeeper的缺点
1.ZooKeeper 是用 Java 编写的，部署较繁琐，占用较多的内存资源，同时 ZooKeeper RPC 的序列化机制用的是 Jute，自己实现的 RPC API；




# 参考资料
[etcd实战课](https://time.geekbang.org/column/intro/100069901?tab=catalog)
